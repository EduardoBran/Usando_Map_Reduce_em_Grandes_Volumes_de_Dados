{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dde1bcc",
   "metadata": {},
   "source": [
    "# <center>Conceito MapReduce</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db67d47b",
   "metadata": {},
   "source": [
    "![Example Image](MapReduce.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d9f947",
   "metadata": {},
   "source": [
    "#### A imagem acima ilustra o funcionamento do modelo MapReduce, um dos principais paradigmas de processamento distribuído do Hadoop. O processo é dividido em seis etapas principais:\n",
    "\n",
    "- **Input**: Os dados brutos de entrada, como uma lista de palavras, são fornecidos para o sistema.\n",
    "- **Splitting**: Os dados são divididos em pequenos blocos, que serão processados de forma distribuída.\n",
    "- **Mapping**: Cada bloco passa por uma etapa de mapeamento, onde as palavras são transformadas em pares chave-valor, por exemplo, (\"Deer\", 1), (\"Car\", 1).\n",
    "- **Shuffling**: As chaves semelhantes são agrupadas para garantir que todos os valores associados a uma mesma chave sejam processados juntos.\n",
    "- **Reducing**: Os valores são somados ou processados de acordo com a operação desejada, como contar quantas vezes cada palavra aparece.\n",
    "- **Final Result**: O resultado final é uma lista de palavras e suas respectivas contagens.\n",
    "\n",
    "Isso permite que grandes volumes de dados sejam processados de forma eficiente e paralela.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "# O que é MapReduce?\n",
    "\n",
    "O MapReduce é um modelo de programação distribuído utilizado principalmente em frameworks como o Hadoop para processar grandes volumes de dados. Ele permite que problemas complexos sejam divididos em pequenas partes que podem ser processadas paralelamente em um cluster de servidores. Esse modelo é particularmente útil para cenários de Big Data, onde o volume de dados é grande demais para ser processado de maneira eficiente em uma única máquina.\n",
    "\n",
    "### Como Funciona o Modelo MapReduce\n",
    "\n",
    "O modelo MapReduce é composto por duas fases principais: **Map** (Mapeamento) e **Reduce** (Redução), além de uma fase intermediária chamada **Shuffle**.\n",
    "\n",
    "- **1. Fase de Mapeamento (Map)**: O processo começa com o cientista de dados analisando o problema e definindo como os dados de entrada serão representados em pares de chave e valor. Por exemplo, em uma contagem de palavras em um conjunto de textos, as palavras individuais podem ser as chaves e a contagem (geralmente 1) seria o valor associado.\n",
    "\n",
    "O cientista de dados desenvolve um programa de mapeamento (Mapper), que aplica essas regras de negócios, \"quebrando\" os dados de entrada em pequenos pares de chave/valor. Cada bloco de dados de entrada é então processado pelo Mapper, que gera os pares conforme definido no código.\n",
    "\n",
    "**Exemplo**: Se os dados de entrada forem \"Deer, Bear, River, Car\", o Mapper pode gerar os seguintes pares: (\"Deer\", 1), (\"Bear\", 1), (\"River\", 1), (\"Car\", 1).\n",
    "\n",
    "<br>\n",
    "\n",
    "- **2. Fase Intermediária** - Shuffle: Após a fase de mapeamento, ocorre a fase de Shuffle. O Shuffle é executado automaticamente pelo framework (neste caso, o Hadoop), sem que o cientista de dados precise intervir diretamente. A função dessa fase é agrupar todos os pares de chave/valor gerados pela etapa de mapeamento.\n",
    "\n",
    "**Exemplo**: Se em várias partes do texto foram encontradas várias ocorrências da palavra \"Car\", o Shuffle agrupará todas essas ocorrências em um único lugar para que possam ser processadas na fase seguinte.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **3. Fase de Redução (Reduce)**: Na fase de Reduce, os pares agrupados pelo Shuffle são processados para gerar o resultado final. O cientista de dados define como será a redução dos dados. No caso da contagem de palavras, a redução pode ser simplesmente somar os valores para cada chave.\n",
    "\n",
    "**Exemplo**: Se os pares de chave/valor após o Shuffle são (\"Car\", [1, 1, 1]), a fase de redução somará esses valores, resultando em (\"Car\", 3).\n",
    "\n",
    "Essa fase de redução retorna a informação processada e consolidada que o cientista de dados precisa para resolver o problema em questão. No exemplo, a saída seria uma lista das palavras e suas respectivas contagens, como (\"Car\", 3), (\"Deer\", 2), (\"Bear\", 2).\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## Papel do Cientista de Dados\n",
    "\n",
    "O cientista de dados desempenha um papel crucial no processo, pois é ele quem define como os dados serão estruturados e processados nas fases de Map e Reduce. Isso inclui:\n",
    "\n",
    "- **Definir Chaves e Valores**: Cabe ao cientista de dados determinar o que será tratado como chave e o que será valor, de acordo com o problema específico. No exemplo de contagem de palavras, as palavras são as chaves e o número de ocorrências são os valores. No entanto, em outros problemas, como processamento de logs ou análise de transações, as definições de chave/valor podem variar.\n",
    "\n",
    "- **Criar o Mapper**: O cientista de dados escreve o código do Mapper que implementa as regras de negócio e transforma os dados brutos em pares de chave/valor que possam ser processados.\n",
    "\n",
    "- **Configurar o Reducer**: Além disso, o cientista de dados desenvolve o código da fase de redução, que especifica como os dados agrupados na fase de Shuffle serão consolidados para produzir o resultado final.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## Benefícios do Modelo MapReduce\n",
    "\n",
    "- **Escalabilidade**: O MapReduce é altamente escalável, capaz de processar grandes volumes de dados ao distribuir o trabalho entre vários nós em um cluster.\n",
    "\n",
    "- **Paralelismo**: Ao dividir o trabalho em pequenas tarefas (Map e Reduce), o processamento pode ser feito paralelamente, o que acelera o tempo de execução.\n",
    "\n",
    "- **Tolerância a Falhas**: O Hadoop, por exemplo, é projetado para lidar com falhas de hardware. Caso algum nó falhe, o framework redireciona automaticamente as tarefas para outros nós, garantindo a continuidade do processamento.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "# Conclusão\n",
    "\n",
    "O MapReduce é um modelo poderoso para processamento de grandes volumes de dados distribuídos. Embora o framework cuide da distribuição e coordenação do trabalho, o sucesso da aplicação depende diretamente do cientista de dados, que deve programar as fases de Map e Reduce de acordo com as necessidades do problema a ser resolvido.\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "# Workflow do Map Reduce\n",
    "\n",
    "<br>\n",
    "\n",
    "![Example Image](WorkflowMapReduce2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee4ef4",
   "metadata": {},
   "source": [
    "### Como o MapReduce utiliza a computação distribuída?\n",
    "\n",
    "Nós temos basicamente 4 etapas de funcionamento do MapReduce através de Computação Distribuída que chamamos de Workflow do MapReduce:\n",
    "\n",
    "- **Agendamento**: Os jobs são divididos em pedaços menores chamados tarefas (tasks). Essas tarefas são distribuídas e agendadas por um sistema de gerenciamento de recursos, como o YARN (Yet Another Resource Negotiator), que coordena a alocação de recursos nos diversos nós de um cluster.\n",
    "\n",
    "- **Localização de Tarefas**: As tarefas são alocadas nos nós que armazenam os segmentos de dados. Ou seja, ao invés de mover os dados até o código, o código é movido até os nós onde os dados estão armazenados. Isso melhora a eficiência do processamento, aproveitando a localização dos dados no cluster.\n",
    "\n",
    "- **Tratamento de Erros**: Falhas são esperadas em sistemas distribuídos. Quando ocorrem erros ou falhas em algum nó, o MapReduce é projetado para ser tolerante a falhas, reencaminhando as tarefas para outros nós do cluster automaticamente, sem interromper o processo.\n",
    "\n",
    "- **Sincronização de Dados**: Durante o processamento, os dados são agrupados e movidos entre os nós de maneira aleatória, o que garante que as etapas de mapeamento e redução sejam realizadas de forma eficiente. O framework do MapReduce é responsável por coordenar tanto o input quanto o output, garantindo que os dados estejam sincronizados e corretamente processados.\n",
    "\n",
    "Essas quatro etapas garantem que o MapReduce utilize a computação distribuída para processar grandes volumes de dados de maneira eficiente e escalável.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "# Processo de Recuperação a Falhas do MapReduce\n",
    "\n",
    "O **Processo de Recuperação a Falhas do MapReduce**, que é uma parte crucial para garantir a continuidade e a confiabilidade do processamento distribuído. O Hadoop, usando o modelo MapReduce, foi projetado para ser resiliente a falhas, especialmente em ambientes distribuídos, onde erros podem ocorrer com frequência. O processo é dividido nas seguintes etapas:\n",
    "\n",
    "1. **Os processos de Task enviam sinais ao TaskTracker**: \n",
    "   Cada tarefa (task) que está sendo executada envia sinais de \"vida\" para o componente TaskTracker, que monitora o andamento das tarefas.\n",
    "\n",
    "2. **Os TaskTrackers enviam sinais ao JobTracker**: \n",
    "   O TaskTracker, responsável por gerenciar as tarefas no nó específico, também envia sinais regulares ao JobTracker, que é o mestre responsável por gerenciar todo o processo de execução das tarefas no cluster.\n",
    "\n",
    "3. **Tasks que levam mais de 10 minutos para responder ou emitem uma exceção são finalizadas pelo TaskTracker**: \n",
    "   Se uma tarefa não responde dentro de um tempo limite (geralmente 10 minutos) ou gera uma exceção, o TaskTracker considera que ela falhou e a encerra.\n",
    "\n",
    "4. **O TaskTracker reporta as Tasks com erro para o JobTracker**: \n",
    "   Após identificar uma falha, o TaskTracker informa o JobTracker sobre as tarefas que falharam. O JobTracker, então, toma medidas para garantir que essas tarefas sejam processadas corretamente.\n",
    "\n",
    "5. **O JobTracker reagenda as Tasks que falharam em TaskTrackers diferentes**: \n",
    "   O JobTracker tenta reatribuir as tarefas que falharam para outros nós (TaskTrackers) no cluster, buscando garantir que a execução das tarefas continue sem interrupções.\n",
    "\n",
    "6. **Se uma Task falhar mais de 4 vezes, o job inteiro falha**: \n",
    "   Em um cenário onde uma tarefa falha repetidamente (geralmente após 4 tentativas), o JobTracker declara a falha do job inteiro. Isso pode acontecer por uma série de motivos, como falhas de hardware ou erros graves no código.\n",
    "\n",
    "Esse mecanismo de recuperação a falhas é uma das características que tornam o Hadoop MapReduce altamente tolerante a falhas, assegurando que, mesmo em ambientes com alta distribuição e múltiplos nós, o sistema continue funcionando de maneira confiável.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfbbbce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1cee6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e226404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a0de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed073b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5248208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
