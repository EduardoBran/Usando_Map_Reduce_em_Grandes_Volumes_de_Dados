{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac383121-cdaa-4cbc-a07e-77131428d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a9bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset\n",
    "dataset = pd.read_csv('Datasets/spot.csv')\n",
    "\n",
    "# Mostrar uma amostra dos dados\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f746b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar informações do dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfbe711",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 3. Pré-processamento dos Dados\n",
    "Vamos preparar o dataset para o modelo. Isso inclui normalizar as features numéricas e codificar as variáveis categóricas, se necessário. Nesse caso, key é uma feature categórica que será codificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe41aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar as features relevantes e a variável alvo 'prediction'\n",
    "numeric_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "categorical_feature = ['key']\n",
    "\n",
    "# Normalizar as features numéricas\n",
    "scaler = StandardScaler()\n",
    "scaled_numeric = scaler.fit_transform(dataset[numeric_features])\n",
    "\n",
    "# Codificar a feature categórica 'key' com o argumento correto\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_categorical = encoder.fit_transform(dataset[categorical_feature])\n",
    "\n",
    "# Combinar as features numéricas e categóricas\n",
    "X = np.hstack([scaled_numeric, encoded_categorical])\n",
    "\n",
    "# Definir a variável de saída 'prediction'\n",
    "y = dataset['prediction'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865d0335",
   "metadata": {},
   "source": [
    "# 4. Divisão do Dataset\n",
    "Agora, dividimos o dataset em conjuntos de treinamento e teste para avaliação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e2e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir o dataset em treinamento e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajuste do formato de entrada para o modelo LSTM\n",
    "# Expande a dimensão de 'timesteps' para 1\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Agora o formato das entradas será (batch_size, 1, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606b8703",
   "metadata": {},
   "source": [
    "# 5. Construção do Modelo LSTM\n",
    "Aqui, utilizamos um modelo LSTM que aprende padrões temporais e gera novas sequências com base nas features de entrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4268f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo LSTM\n",
    "model = Sequential()\n",
    "\n",
    "# Primeira camada LSTM\n",
    "model.add(LSTM(128, input_shape=(timesteps, features), return_sequences=True))\n",
    "\n",
    "# Segunda camada LSTM\n",
    "model.add(LSTM(128))\n",
    "\n",
    "# Camada densa de saída ajustada para prever 1 valor (a 'prediction')\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Treinamento do modelo\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f289ebe",
   "metadata": {},
   "source": [
    "# 6. Avaliação do Modelo\n",
    "Agora, avalie o desempenho do modelo para garantir que ele esteja funcionando conforme o esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação com o conjunto de teste\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Loss: {loss}\")\n",
    "\n",
    "# Visualizar a curva de perda durante o treinamento\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65631733",
   "metadata": {},
   "source": [
    "# 7. Geração de Novas Músicas\n",
    "Para gerar novas sequências de música, você pode usar uma semente inicial (um conjunto de características de uma música) e deixar o modelo prever as próximas etapas.\n",
    "\n",
    "<br>\n",
    "\n",
    "### 7.1 Escolher uma Semente (Input Inicial)\n",
    "\n",
    "Usaremos uma linha específica da música \"Polly\" do Nirvana para inicializar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf79f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133de7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1004696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar a primeira ocorrência de \"Polly\" do Nirvana\n",
    "nirvana_polly = dataset.loc[(dataset['artists'] == 'Nirvana') & (dataset['name'] == 'Polly')].iloc[0]\n",
    "\n",
    "# Separar as features relevantes\n",
    "numeric_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "categorical_feature = ['key']\n",
    "\n",
    "# Extrair as features numéricas e categóricas\n",
    "polly_features = nirvana_polly[numeric_features + categorical_feature].values.reshape(1, -1)\n",
    "\n",
    "# Normalizar as features numéricas\n",
    "scaled_polly = scaler.transform(polly_features[:, :len(numeric_features)])\n",
    "\n",
    "# Codificar a feature categórica 'key'\n",
    "encoded_key_polly = encoder.transform(polly_features[:, len(numeric_features):])\n",
    "\n",
    "# Combinar as features numéricas e categóricas\n",
    "polly_seed = np.hstack([scaled_polly, encoded_key_polly])\n",
    "\n",
    "# Formatar para o modelo (1, 1, features)\n",
    "polly_seed = polly_seed.reshape(1, 1, polly_seed.shape[1])\n",
    "polly_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = X_test[0].reshape(1, 1, X_test.shape[2])  # Formato (1, timesteps, features)\n",
    "seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133486c8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 7.2 Definir a Quantidade de Passos a Serem Gerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5614c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o número de características que deseja que o modelo gere\n",
    "num_steps = 50  # Por exemplo, gerar 50 passos musicais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ab7483",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 7.3. Gerar Novas Características (Predição Sequencial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b79528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23fe1b0d",
   "metadata": {},
   "source": [
    "# 8. Refinamento e Ajustes\n",
    "Dependendo da qualidade das músicas geradas, você pode fazer ajustes no modelo:\n",
    "\n",
    "- Ajustar o número de camadas LSTM, a quantidade de unidades ou as épocas de treinamento.\n",
    "- Utilizar uma abordagem mais complexa, como Transformers, para melhorar a geração de músicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb462864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9815fb43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca16b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc367f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257e9fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d32a40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d6f252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64899e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f10cb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduardo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2024-10-18 17:06:55.130161: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-18 17:06:55.139255: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-18 17:06:55.150104: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-18 17:06:55.153665: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-18 17:06:55.165418: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-18 17:06:55.846416: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d01ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22a0Ji6EQKkY0tBohlN4Od</td>\n",
       "      <td>There You Are</td>\n",
       "      <td>KirstenLudwig</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.707</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-5.596</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>0.282000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.316</td>\n",
       "      <td>129.856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4J39ZEbwqHwtWLImUKmrn9</td>\n",
       "      <td>88 Days</td>\n",
       "      <td>SaraKingIanOlney</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.401</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-10.749</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.233</td>\n",
       "      <td>155.062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0a12d4HUjOmQSqHqLopWYx</td>\n",
       "      <td>Castaway</td>\n",
       "      <td>ARZLEE</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11.290</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.290</td>\n",
       "      <td>83.988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0u7JZm9ORerlZnnxxSdMwl</td>\n",
       "      <td>Lonely</td>\n",
       "      <td>Hayleau</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.709</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-3.921</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.577</td>\n",
       "      <td>98.954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0wuy2BYIVLbflFDqnR9Jay</td>\n",
       "      <td>Orsay</td>\n",
       "      <td>TheSvens</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.858</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.283</td>\n",
       "      <td>122.992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id           name           artists  danceability  \\\n",
       "0  22a0Ji6EQKkY0tBohlN4Od  There You Are     KirstenLudwig         0.487   \n",
       "1  4J39ZEbwqHwtWLImUKmrn9        88 Days  SaraKingIanOlney         0.335   \n",
       "2  0a12d4HUjOmQSqHqLopWYx       Castaway            ARZLEE         0.553   \n",
       "3  0u7JZm9ORerlZnnxxSdMwl         Lonely           Hayleau         0.670   \n",
       "4  0wuy2BYIVLbflFDqnR9Jay          Orsay          TheSvens         0.610   \n",
       "\n",
       "   energy  key  loudness  speechiness  acousticness  instrumentalness  \\\n",
       "0   0.707  9.0    -5.596       0.0304        0.3340          0.282000   \n",
       "1   0.401  3.0   -10.749       0.0333        0.1340          0.582000   \n",
       "2   0.422  1.0   -11.290       0.0314        0.1100          0.000032   \n",
       "3   0.709  8.0    -3.921       0.0406        0.0169          0.000630   \n",
       "4   0.444  0.0   -11.858       0.0316        0.0486          0.886000   \n",
       "\n",
       "   liveness  valence    tempo  prediction  \n",
       "0    0.1050    0.316  129.856           1  \n",
       "1    0.1340    0.233  155.062           0  \n",
       "2    0.1190    0.290   83.988           1  \n",
       "3    0.0542    0.577   98.954           1  \n",
       "4    0.1280    0.283  122.992           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar o dataset\n",
    "dataset = pd.read_csv('Datasets/spot.csv')\n",
    "\n",
    "# Mostrar uma amostra dos dados\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4e5e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar as features relevantes e a variável alvo 'prediction'\n",
    "numeric_features = ['danceability', 'energy', 'loudness', 'speechiness', \n",
    "                    'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "categorical_feature = ['key']\n",
    "\n",
    "# Normalizar as features numéricas\n",
    "scaler = StandardScaler()\n",
    "scaled_numeric = scaler.fit_transform(dataset[numeric_features])\n",
    "\n",
    "# Codificar a feature categórica 'key'\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_categorical = encoder.fit_transform(dataset[categorical_feature])\n",
    "\n",
    "# Combinar as features numéricas e categóricas\n",
    "X = np.hstack([scaled_numeric, encoded_categorical])\n",
    "\n",
    "# Definir a variável de saída 'prediction'\n",
    "y = dataset['prediction'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c059ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir o dataset em treinamento e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajuste do formato de entrada para o modelo LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196318e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduardo/anaconda3/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Construção do modelo LSTM\n",
    "model = Sequential()\n",
    "\n",
    "# Primeira camada LSTM\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.3))  # Para evitar overfitting\n",
    "\n",
    "# Segunda camada LSTM\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Camada densa de saída ajustada para prever 1 valor (a 'prediction')\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3146b546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential, built=True>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b276f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.3349 - val_loss: 0.0587\n",
      "Epoch 2/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0634 - val_loss: 0.0260\n",
      "Epoch 3/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.0357 - val_loss: 0.0180\n",
      "Epoch 4/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0265 - val_loss: 0.0147\n",
      "Epoch 5/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0228 - val_loss: 0.0116\n",
      "Epoch 6/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0186 - val_loss: 0.0109\n",
      "Epoch 7/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0165 - val_loss: 0.0089\n",
      "Epoch 8/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - loss: 0.0149 - val_loss: 0.0084\n",
      "Epoch 9/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0140 - val_loss: 0.0085\n",
      "Epoch 10/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0131 - val_loss: 0.0089\n",
      "Epoch 11/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0131 - val_loss: 0.0074\n",
      "Epoch 12/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0133 - val_loss: 0.0076\n",
      "Epoch 13/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0123 - val_loss: 0.0064\n",
      "Epoch 14/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0119 - val_loss: 0.0065\n",
      "Epoch 15/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0119 - val_loss: 0.0083\n",
      "Epoch 16/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0114 - val_loss: 0.0067\n",
      "Epoch 17/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0110 - val_loss: 0.0068\n",
      "Epoch 18/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0103 - val_loss: 0.0056\n",
      "Epoch 19/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0109 - val_loss: 0.0060\n",
      "Epoch 20/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0108 - val_loss: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0114 - val_loss: 0.0073\n",
      "Epoch 22/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0103 - val_loss: 0.0069\n",
      "Epoch 23/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0106 - val_loss: 0.0053\n",
      "Epoch 24/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0097 - val_loss: 0.0053\n",
      "Epoch 25/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0099 - val_loss: 0.0064\n",
      "Epoch 26/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 27/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 28/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 29/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0102 - val_loss: 0.0050\n",
      "Epoch 30/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 31/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0095 - val_loss: 0.0058\n",
      "Epoch 32/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0100 - val_loss: 0.0076\n",
      "Epoch 33/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0097 - val_loss: 0.0054\n",
      "Epoch 34/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0098 - val_loss: 0.0064\n",
      "Epoch 35/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 36/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0059\n",
      "Epoch 37/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 38/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 39/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0085 - val_loss: 0.0057\n",
      "Epoch 40/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0090 - val_loss: 0.0065\n",
      "Epoch 41/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 42/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 43/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 44/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0089 - val_loss: 0.0065\n",
      "Epoch 45/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0055\n",
      "Epoch 46/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 47/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 48/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 49/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 50/50\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0083 - val_loss: 0.0063\n"
     ]
    }
   ],
   "source": [
    "# Treinamento do modelo\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b446a4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9746120e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731b429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
