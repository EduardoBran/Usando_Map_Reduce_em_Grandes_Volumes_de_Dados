{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ccc3875",
   "metadata": {},
   "source": [
    "# <center> Conceitos Apache Hadoop e Apache HDFS</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c277334",
   "metadata": {},
   "source": [
    "**O Curso está dividido em duas partes**:\n",
    "\n",
    "- Parte 1: cap 2, 3 e 4 o foco é a **instalação o Hadoop e seu ecossistema**, assim como configuração Cluster Hadoop para armazenar Big Data.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Parte 2: cap 5, 6 e 7 o foco é como armazenar e recuperar dado com HDFS, como executar <i>jobs</i>, processar consultas e integração com banco de dados relacionais\n",
    "\n",
    "<br>\n",
    "\n",
    "- Parte 3: cap 8 o foco é estudar como usar o <i>Apache Mahout</i> para aplicar Técnicas de **Machine Learning** em dados armzenados no Apache Hadoop HDFS\n",
    "\n",
    "<br>\n",
    "\n",
    "- Parte 4: cap 9 o foco é estudar como usar Hadoop e Spark juntos.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# O que será aprendido neste curso?\n",
    "\n",
    "- Conceitos e definições de Big Data, Hadoop. Ecossistema Hadoop e Spark\n",
    "- Como planejar, instalar e configurar um cluster Hadoop\n",
    "- Como planejar, instalar e configurar o Ecossitema Hadoop (Hive, Hbase, Zookeeper, Flume, Ooozie, Ambari, Sqoop, Spark e Storm)\n",
    "- Configuração e utilização do HDFS e configurações avançadas do cluster Hadoop\n",
    "- Administração e Manutenção do Hadoop e Spark\n",
    "- Machine Learning com Apache Mahout\n",
    "- Importação e Exportação de dados e ETL com Sqoop\n",
    "- Principais distribuições Hadoop do mercado: Cloudera e Hortonworks\n",
    "- Infraestruturas de Big Data\n",
    "- Análise de Big Data\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# Apache Hadoop\n",
    "\n",
    "<br>\n",
    "\n",
    "### O que é Apache Hadoop ?\n",
    "\n",
    "- O Apache Hadoop é um framework de software open-source usado para armazenar e processar grandes volumes de dados em um ambiente distribuído. Ele utiliza clusters de servidores para garantir escalabilidade e alta eficiência no processamento paralelo de dados.\n",
    "\n",
    "### Para que serve o Apache Hadoop?\n",
    "\n",
    "- O Hadoop é utilizado para armazenar, processar e analisar grandes quantidades de dados de forma distribuída. Ele divide os dados entre múltiplos servidores, permitindo o processamento simultâneo, o que acelera a análise de grandes volumes de informações.\n",
    "\n",
    "### Como o uso do Apache Hadoop traz benefícios para empresas?\n",
    "\n",
    "- O Hadoop oferece benefícios como escalabilidade, economia e eficiência. Empresas podem armazenar e processar Big Data rapidamente, obtendo insights valiosos para tomada de decisões, previsões de mercado e análises operacionais, usando hardware comum e reduzindo custos com infraestrutura.\n",
    "\n",
    "### O que é o ecossistema do Apache Hadoop?\n",
    "\n",
    "- O ecossistema do Hadoop é um conjunto de ferramentas que suportam o armazenamento, processamento e análise de dados em larga escala. Inclui componentes como o HDFS (armazenamento), MapReduce (processamento), Hive e HBase (bancos de dados), Zookeeper (coordenação), Flume e Sqoop (integração de dados) e Spark (processamento rápido em memória).\n",
    "\n",
    "#### Principais Projetos do Ecossistema Apache Hadoop\n",
    "\n",
    "- **Hadoop Distributed File System (HDFS)**: O sistema de arquivos distribuído que permite o armazenamento de grandes volumes de dados em um cluster de servidores. Ele é projetado para alta disponibilidade, replicação de dados e gerenciamento de falhas.\n",
    "\n",
    "- **MapReduce**: O modelo de processamento de dados distribuído do Hadoop, que permite processar grandes conjuntos de dados de forma paralela, distribuindo tarefas entre diferentes servidores.\n",
    "\n",
    "- **YARN (Yet Another Resource Negotiator)**: O sistema de gerenciamento de recursos do Hadoop que aloca e gerencia recursos computacionais em clusters para diferentes aplicações.\n",
    "\n",
    "- **Hive**: Um sistema de data warehouse que permite a consulta e análise de grandes volumes de dados armazenados no HDFS utilizando uma linguagem semelhante ao SQL, chamada HiveQL.\n",
    "\n",
    "- **HBase**: Um banco de dados NoSQL que funciona sobre o HDFS e é otimizado para grandes volumes de dados e consultas em tempo real.\n",
    "\n",
    "- **Pig**: Uma plataforma de alto nível para processamento de dados em Hadoop, com sua própria linguagem, chamada Pig Latin, que simplifica o desenvolvimento de trabalhos MapReduce.\n",
    "\n",
    "- **Sqoop**: Ferramenta usada para importar e exportar dados entre sistemas de banco de dados relacionais (como MySQL e PostgreSQL) e o Hadoop.\n",
    "\n",
    "- **Flume**: Sistema de ingestão de dados que coleta, agrega e move grandes volumes de dados de várias fontes para o HDFS ou HBase.\n",
    "\n",
    "- **Zookeeper**: Um serviço de coordenação para aplicações distribuídas, garantindo alta disponibilidade e sincronização entre componentes do ecossistema.\n",
    "\n",
    "- **Oozie**: Um sistema de agendamento de workflows que permite gerenciar e coordenar jobs MapReduce, Hive, Pig e outros dentro do Hadoop.\n",
    "\n",
    "- **Spark**: Um motor de processamento de dados rápido e de propósito geral que pode ser integrado ao Hadoop, permitindo o processamento em memória para tarefas mais rápidas e eficientes, especialmente em machine learning e big data analytics.\n",
    "\n",
    "- **Ambari**: Uma ferramenta de gerenciamento e monitoramento de clusters Hadoop, que oferece uma interface gráfica para gerenciar, provisionar e monitorar todo o ecossistema.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# Apache HDFS\n",
    "\n",
    "<br>\n",
    "\n",
    "### O que é Apache HDFS ?\n",
    "\n",
    "- O Apache Hadoop Distributed File System (HDFS) é o sistema de arquivos distribuído do Apache Hadoop, projetado para armazenar grandes volumes de dados em clusters de servidores. Ele divide grandes conjuntos de dados em blocos menores que são distribuídos entre diferentes nós do cluster. O HDFS é altamente escalável, tolerante a falhas e otimizado para leitura sequencial de grandes arquivos, o que o torna ideal para cenários de Big Data.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Arquitetura do HDFS\n",
    "\n",
    "- **Namenode**: É o nó mestre que gerencia o sistema de arquivos e controla o acesso aos arquivos pelos clientes. Ele mantém o metadata (informações sobre quais blocos formam um arquivo, em quais nós estão armazenados, etc.). Se o Namenode falhar, o cluster inteiro pode se tornar inacessível, por isso é um componente crítico.\n",
    "\n",
    "- **Datanodes**: São os nós de armazenamento que contêm os dados reais. Eles armazenam e recuperam blocos de dados sob a direção do Namenode. Os Datanodes também reportam periodicamente o status de armazenamento para o Namenode, garantindo que ele saiba quais blocos estão disponíveis e replicados.\n",
    "\n",
    "- **Blocos de Dados**: O HDFS divide os arquivos em blocos menores (normalmente de 128 MB ou 64 MB) para que possam ser armazenados em diferentes Datanodes. Cada bloco é replicado em múltiplos nós para garantir alta disponibilidade e tolerância a falhas.\n",
    "\n",
    "- **Replicação**: O HDFS replica os blocos de dados em vários Datanodes (geralmente três cópias por padrão) para garantir que os dados ainda estejam acessíveis mesmo em caso de falha de algum nó.\n",
    "\n",
    "- **Namenode Secundário (Secondary Namenode)**: Apesar do nome, ele não é um backup completo do Namenode, mas um auxiliar que ajuda a manter o sistema ao realizar checkpoints do metadata. Isso evita a sobrecarga do Namenode principal, mas em caso de falha, o Namenode Secundário não pode substituir o principal automaticamente.\n",
    "\n",
    "- **Client**: O cliente HDFS é o componente que interage com o sistema de arquivos. Ele envia solicitações ao Namenode para operações como leitura e escrita de arquivos e interage com os Datanodes para manipular os blocos de dados.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# Definindo Map Reduce\n",
    "\n",
    "<br>\n",
    "\n",
    "MapReduce é o modelo de processamento distribuído usado no Hadoop para manipular grandes volumes de dados. Ele divide o processamento de dados em duas fases principais: Map e Reduce.\n",
    "\n",
    "- **Fase Map**: Nesta fase, os dados de entrada são divididos em pequenas partes (chamados \"splits\") e processados paralelamente por diferentes nós do cluster. O objetivo é transformar os dados de entrada em pares chave-valor intermediários. Cada nó processa seu fragmento de dados localmente, sem comunicação com outros nós.\n",
    "\n",
    "- **Fase Reduce**: Após o processamento da fase Map, os pares chave-valor intermediários são agrupados por chave e passados para a fase Reduce. Nesta fase, os dados agrupados são processados e reduzidos para gerar o resultado final. Essa operação geralmente envolve a agregação dos dados ou cálculos finais sobre os dados agrupados.\n",
    "\n",
    "O MapReduce é extremamente eficiente para manipular grandes conjuntos de dados, pois distribui a carga de processamento entre vários nós do cluster, possibilitando o processamento paralelo e escalável.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# Hadoop x Banco de Dados Relacionais\n",
    "\n",
    "<br>\n",
    "\n",
    "Hadoop e Bancos de Dados Relacionais (RDBMS) têm abordagens diferentes para armazenar e processar dados, com características específicas que os tornam adequados para diferentes cenários:\n",
    "\n",
    "#### Hadoop\n",
    "\n",
    "- Armazena e processa grandes volumes de dados não estruturados e semiestruturados.\n",
    "- Utiliza um sistema de arquivos distribuído (HDFS) que é altamente escalável e tolerante a falhas.\n",
    "- Focado em processamento em batch (lotes), ideal para análise de Big Data e dados em larga escala, distribuídos em muitos nós.\n",
    "- Projetado para processamento paralelo e uso intensivo de recursos de hardware comuns.\n",
    "- Melhor para situações em que a escalabilidade e o volume massivo de dados são prioridades, como processamento de logs, análise de redes sociais, ou dados de sensores.\n",
    "\n",
    "#### Bancos de Dados Relacionais (RDBMS):\n",
    "\n",
    "- Estruturam dados em tabelas e utilizam SQL para consulta e manipulação de dados.\n",
    "- Ideal para dados transacionais e estruturados, como sistemas de pagamento, contabilidade e controle de estoque.\n",
    "- Armazenamento centralizado, normalmente em servidores de alto desempenho, com backup e alta disponibilidade, mas menor escalabilidade comparada ao Hadoop.\n",
    "- Otimizado para consultas em tempo real e transações que precisam garantir integridade, atomicidade e consistência.\n",
    "- Melhor para operações transacionais e manipulação de conjuntos de dados menores e estruturados, onde a latência baixa é crucial.\n",
    "\n",
    "Em resumo, enquanto o Hadoop é mais adequado para o processamento de grandes volumes de dados em lote (Big Data), os bancos de dados relacionais são melhores para transações em tempo real e manipulação de dados estruturados, com ênfase na consistência e integridade dos dados.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# Por que Cientista de Dados precisam conhecer o Hadoop\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Hadoop é Open Source**: Sendo de código aberto, o Hadoop pode ser utilizado e adaptado sem custos, tornando-o acessível para empresas de todos os tamanhos.\n",
    "\n",
    "- **Hadoop é o framework mais completo para Big Data**: Ele oferece uma solução escalável e flexível para armazenar e processar grandes volumes de dados estruturados e não estruturados.\n",
    "\n",
    "- **Oracle utiliza Hadoop em suas soluções de Big Data Analytics**: A Oracle integrou Hadoop para otimizar a análise de grandes volumes de dados em suas soluções corporativas.\n",
    "\n",
    "- **Microsoft oferece Hadoop em suas soluções em nuvem**: A Microsoft incorporou Hadoop na plataforma Azure para permitir o processamento de Big Data na nuvem.\n",
    "\n",
    "- **Hadoop é usado por grandes empresas**: Empresas como Facebook e Google utilizam Hadoop para gerenciar e processar enormes volumes de dados.\n",
    "\n",
    "- **MapReduce é essencial para Cientistas de Dados**: O conhecimento do paradigma de processamento MapReduce é fundamental para lidar com Big Data de forma eficiente.\n",
    "\n",
    "- **Hadoop é uma habilidade muito procurada**: O conhecimento de Hadoop é altamente valorizado no mercado de trabalho para cientistas de dados.\n",
    "\n",
    "- **Faltam profissionais qualificados em Hadoop**: Há uma alta demanda e poucas pessoas com experiência em Hadoop, criando grandes oportunidades de emprego.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# Modos de Execução do Hadoop\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Modo Local (StandAlone)**: O Hadoop é executado em uma única máquina sem HDFS ou distribuição de tarefas. Usado para desenvolvimento e testes, tudo é processado localmente no sistema de arquivos da máquina, sem a necessidade de configuração de cluster.\n",
    "\n",
    "- **Modo Pseudo-Distribuído (Pseudo-Distributed)**: O Hadoop é configurado para rodar em um único nó, mas simula um ambiente distribuído. Todos os processos (Namenode, Datanode, etc.) são executados na mesma máquina. Ideal para testes de configuração antes de escalar para um cluster real.\n",
    "\n",
    "- **Modo Totalmente Distribuído (Fully Distributed)**: O Hadoop roda em um cluster completo, com vários nós, utilizando HDFS e distribuindo as tarefas entre diferentes servidores. Esse modo é usado para processamento real de grandes volumes de dados e é altamente escalável e tolerante a falhas.\n",
    "\n",
    "<br>\n",
    "\n",
    "> Para alternar entre essas configurações é necessário a edição de três arquivos: **core-site.xml**, **hdfs-site.xml** e **mapred-site.xml**.\n",
    "\n",
    "> Cada arquivo desse pode receber até 200 parâmetros e caso não configure manualmente algum desses parâmetros o Hadoop assume um valor <i>default</i>.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# Instalando o Hadoop no Ubuntu: Comparação entre Instalação Direta e Máquina Virtual\n",
    "\n",
    "<br>\n",
    "\n",
    "Se você instalar o Hadoop diretamente no seu Linux Ubuntu, você terá acesso completo às suas configurações, sem limitações. Você pode personalizar e configurar todos os arquivos de configuração do Hadoop, como `core-site.xml`, `hdfs-site.xml`, e `mapred-site.xml`, para ajustar o comportamento do sistema de acordo com suas necessidades.\n",
    "\n",
    "### As principais diferenças entre instalar diretamente no sistema e usar uma máquina virtual são:\n",
    "\n",
    "#### Instalando diretamente no Ubuntu:\n",
    "\n",
    "- **Acesso total às configurações**: Você pode configurar o Hadoop do jeito que quiser, sem limitações.\n",
    "- **Melhor desempenho**: Como não há sobrecarga de virtualização, o desempenho do Hadoop pode ser melhor ao rodar diretamente no sistema operacional.\n",
    "- **Interação direta com seu sistema**: Você pode integrar o Hadoop mais facilmente com outras ferramentas e serviços já instalados no seu Ubuntu.\n",
    "- **Risco de interferência no sistema**: Alterações ou falhas no Hadoop podem impactar seu sistema principal, especialmente em questões como permissões, dependências de pacotes, etc.\n",
    "\n",
    "#### Usando uma máquina virtual:\n",
    "\n",
    "- **Isolamento total**: O Hadoop é executado em um ambiente separado, então qualquer erro ou problema no Hadoop não afetará o sistema principal.\n",
    "- **Flexibilidade**: Você pode criar e recriar ambientes Hadoop isolados, testar diferentes configurações e versões, sem risco de impactar seu sistema nativo.\n",
    "- **Sobrecarga de recursos**: A virtualização pode exigir mais recursos do sistema, o que pode afetar o desempenho.\n",
    "- **Backup e reversibilidade**: É mais fácil realizar snapshots de máquinas virtuais e voltar para uma versão anterior se algo der errado.\n",
    "\n",
    "### Conclusão\n",
    "\n",
    "Se o objetivo é usar o Hadoop no seu Ubuntu para testes, desenvolvimento ou produção, não há limitações em configurar o Hadoop diretamente no Linux. O uso de uma máquina virtual só é recomendado caso você deseje um ambiente isolado ou precise testar diferentes configurações e versões de forma segura.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# Arquitetura do Cluster Hadoop\n",
    "\n",
    "<br>\n",
    "\n",
    "Um Cluster Hadoop é um conjunto de máquinas com Hadoop instalado que é criado para armazenar e analisar grandes quantidades de dados, sejam eles estruturados ou não estruturados. Em um Cluster Hadoop, os dados são armazenados e processados ao longo de diversos computadores e tudo isso é feito de forma paralela.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# Workflow de um Cluster Hadoop\n",
    "\n",
    "<br>\n",
    "\n",
    "1. **Divisão de dados:** Os dados são quebrados em blocos menores e distribuídos entre os diversos nós do cluster, garantindo redundância e disponibilidade.\n",
    "  \n",
    "2. **Processamento paralelo:** Frameworks como **MapReduce** ou **Apache Spark** processam esses dados em paralelo, utilizando pares de chave-valor para executar tarefas de forma eficiente e escalável.\n",
    "\n",
    "3. **Armazenamento de resultados:** Após o processamento, os resultados são armazenados novamente como blocos no cluster, aproveitando a mesma arquitetura distribuída.\n",
    "\n",
    "4. **Leitura dos resultados:** Esses resultados ficam disponíveis para serem acessados e analisados por qualquer serviço ou aplicação que precise dos dados processados.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Função do NameNode no Processo de Gravação no HDFS\n",
    "\n",
    "O **NameNode** é o núcleo central da arquitetura HDFS, responsável pela gestão das informações de metadados do sistema de arquivos. No processo de gravação, o NameNode desempenha um papel crucial:\n",
    "\n",
    "1. **Recepção da Solicitação:** Quando um cliente solicita a gravação de um arquivo no HDFS, o NameNode recebe a solicitação e divide o arquivo em blocos.\n",
    "\n",
    "2. **Alocação de DataNodes:** O NameNode, então, aloca quais **DataNodes** serão responsáveis por armazenar cada bloco do arquivo. Ele escolhe os DataNodes baseados em critérios como disponibilidade e balanceamento de carga.\n",
    "\n",
    "3. **Metadados:** O NameNode não armazena os dados reais, mas mantém uma tabela de metadados que mapeia os blocos de dados aos respectivos DataNodes. Isso inclui informações sobre a localização de cada bloco e sua replicação.\n",
    "\n",
    "4. **Monitoramento:** Durante o processo de gravação, o NameNode monitora a replicação dos blocos e garante que as réplicas sejam armazenadas corretamente nos DataNodes, conforme a política de replicação do cluster.\n",
    "\n",
    "5. **Confirmação:** Após a conclusão do processo de gravação e replicação nos DataNodes, o NameNode envia uma confirmação ao cliente, indicando que o arquivo foi armazenado com sucesso.\n",
    "\n",
    "Em resumo, o NameNode coordena todo o fluxo de gravação de dados no HDFS, mantendo o controle dos blocos e assegurando que os dados sejam distribuídos e replicados corretamente no cluster.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "\n",
    "# Planejamento do Cluster Hadoop\n",
    "\n",
    "<br>\n",
    "\n",
    "## Fatores para o Planejamento do Cluster Hadoop\n",
    "\n",
    "Ao planejar um **Cluster Hadoop**, é essencial considerar uma série de fatores para garantir que ele atenda aos requisitos de desempenho, escalabilidade e disponibilidade. Abaixo estão os principais aspectos que devem ser avaliados:\n",
    "\n",
    "### 1. Objetivo\n",
    "O planejamento do cluster deve estar alinhado com o objetivo principal, levando em conta o **volume de dados** e a **alta disponibilidade**. Dependendo da quantidade de dados que serão processados e armazenados, o cluster precisa ser dimensionado adequadamente para suportar grandes volumes sem comprometer a disponibilidade dos serviços.\n",
    "\n",
    "- **Volume de Dados**: O cluster deve ser capaz de armazenar e processar grandes volumes de dados de forma eficiente.\n",
    "- **Alta Disponibilidade**: A arquitetura deve garantir que os serviços críticos, como o NameNode e o JobTracker, estejam sempre disponíveis, utilizando configurações de alta disponibilidade para evitar falhas.\n",
    "\n",
    "### 2. Serviços\n",
    "Os serviços essenciais que compõem o cluster Hadoop devem ser considerados na configuração:\n",
    "\n",
    "- **MapReduce**: Composto pelo **JobTracker** (responsável por coordenar a execução dos jobs) e pelo **TaskTracker** (responsável por executar as tarefas).\n",
    "- **HDFS**: O sistema de arquivos distribuído do Hadoop, composto pelo **NameNode** (gerenciador de metadados) e pelos **DataNodes** (armazenamento dos blocos de dados).\n",
    "- **Storage**: Sistemas de armazenamento como **NFS** (Network File System) ou **SAN** (Storage Area Network) podem ser integrados ao cluster para garantir maior flexibilidade e escalabilidade no armazenamento.\n",
    "\n",
    "### 3. Layout\n",
    "A escolha do layout do cluster depende do estágio do projeto e da finalidade:\n",
    "\n",
    "- **Pseudo-distribuído**: Utilizado para fins de desenvolvimento e testes. Nesse modo, todos os serviços do Hadoop (NameNode, DataNode, JobTracker, TaskTracker) são executados em uma única máquina, simulando um cluster distribuído.\n",
    "- **Totalmente-distribuído**: Utilizado em produção, tanto em ambientes locais quanto em nuvem. Nesse layout, cada serviço do Hadoop roda em nós separados, distribuindo a carga e permitindo maior escalabilidade e confiabilidade.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "O planejamento cuidadoso desses fatores garante que o **Cluster Hadoop** seja dimensionado e configurado de forma eficiente, oferecendo o desempenho e a resiliência necessários para processamento de grandes volumes de dados.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# Quando Usar e Quando Não Usar o HDFS\n",
    "\n",
    "<br>\n",
    "\n",
    "## Quando **não** usar o HDFS?\n",
    "\n",
    "- **Quantidade considerável de arquivos pequenos**: O HDFS não é eficiente para lidar com muitos arquivos pequenos.\n",
    "- **Composições variadas (muitos arquivos em formatos diferentes)**: Quando há grande variação de formatos e tamanhos de arquivos, o HDFS pode não ser a melhor solução.\n",
    "- **Acesso de baixa latência aos dados**: Se sua aplicação requer acesso de baixa latência, o HDFS pode não ser ideal, pois foi otimizado para alto throughput e não baixa latência.\n",
    "\n",
    "---\n",
    "\n",
    "## Quando usar o HDFS?\n",
    "\n",
    "- **Grande quantidade de dados a serem armazenados**: O HDFS é ideal para armazenar grandes volumes de dados distribuídos.\n",
    "- **Streams de dados constantes que requerem acesso**: Quando há fluxos de dados contínuos que precisam ser armazenados e acessados frequentemente.\n",
    "- **Apenas equipamentos simples estão disponíveis**: O HDFS foi projetado para ser executado em hardware simples, sem a necessidade de servidores caros.\n",
    "\n",
    "---\n",
    "\n",
    "## Características do HDFS\n",
    "\n",
    "- **Framework distribuído e tolerante a falhas**: O HDFS é altamente resiliente a falhas e distribuído por design.\n",
    "- **Concebido para grandes volumes de dados**: Ele foi desenvolvido para processar e armazenar grandes quantidades de dados, especialmente em ambientes distribuídos.\n",
    "- **Baseado no Unix**: O HDFS segue princípios de sistemas de arquivos Unix.\n",
    "- **Modelo \"write-once-read-many\" (WORM)**: Os dados são gravados uma vez e podem ser lidos várias vezes, mas não podem ser modificados depois de gravados.\n",
    "- **Eficiente controle de concorrência**: O HDFS gerencia bem o acesso concorrente a dados.\n",
    "- **Redirecionamento de jobs em caso de falhas**: Quando uma falha ocorre, o HDFS redireciona tarefas (jobs) automaticamente para garantir a execução.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dfb744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
